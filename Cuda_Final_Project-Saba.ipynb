{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cuda Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saba6099/Soccer-robot-perception/blob/master/Cuda_Final_Project-Saba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvWDdkhERajK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#import required packages\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import random\n",
        "import numbers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import randperm\n",
        "from torch._utils import _accumulate\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.transforms.functional as F\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from skimage import io, transform\n",
        "import sklearn.metrics as skm\n",
        "import imutils\n",
        "from scipy.spatial import distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02W0XhaKRqHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def New_bnddtls(bnddtls,scaling):\n",
        "    \"\"\" \n",
        "    Calculating the scaled boundary details\n",
        "    Args:\n",
        "    bnddtls: actual details of the boundary box\n",
        "    scaling: scaling factor to change the details of boundary box\n",
        "    Returns:\n",
        "    scaled boundary box details\n",
        "    \"\"\"\n",
        "    bnddtls[0] = bnddtls[0]/scaling\n",
        "    bnddtls[1] = bnddtls[1]/scaling\n",
        "    bnddtls[2][0] = (bnddtls[0, 0]+bnddtls[1, 0]) /2.0\n",
        "    bnddtls[2][1] = (bnddtls[0, 1]+bnddtls[1, 1])/2.0\n",
        "    bnddtls[3][0] = torch.abs(bnddtls[0, 0]-bnddtls[1, 0])\n",
        "    bnddtls[3][1] = torch.abs(bnddtls[0, 1]-bnddtls[1, 1])\n",
        "    return bnddtls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fvIRzK30Veb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_bnddetails(bndvalues):\n",
        "   \"\"\" Finding details of boundary box from xml tag.\n",
        "   Args:\n",
        "   bndvalues: boundary details of the bounding box.\n",
        "    \n",
        "   Returns:\n",
        "   corners of boundary box, center of the box, height and width as a array.\n",
        "   \"\"\"\n",
        "   xmin = int(bndvalues.find('xmin').text)\n",
        "   ymin = int(bndvalues.find('ymin').text)\n",
        "   xmax = int(bndvalues.find('xmax').text)\n",
        "   ymax = int(bndvalues.find('ymax').text)\n",
        "   return np.array((xmin,ymin,xmax,ymax,(xmin+xmax)/2,(ymin+ymax)/2,np.abs(xmax-xmin),np.abs(ymin-ymax))).reshape(-1,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEgwlnglWl44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def HeatMap(bnddtls,filesize):\n",
        "    \"\"\" \n",
        "    Generating heatmap based on boundary details\n",
        "    Args:\n",
        "    bnddtls: actual details of the boundary box\n",
        "    filesize: size of the boundary box\n",
        "\n",
        "    Returns:\n",
        "    heat-map of size filesize/4 with center from bnddtls\n",
        "    \"\"\"\n",
        "    bnddtls.float()\n",
        "    height = bnddtls[3][0]\n",
        "    width  = bnddtls[3][1]\n",
        "    bnddtls = New_bnddtls(bnddtls,4.0)\n",
        "    img_heatmap = torch.zeros(int(filesize[0]/4),int(filesize[1]/4))\n",
        "    size=8\n",
        "    kernel = cv2.getGaussianKernel(size, 8)\n",
        "    kernel = np.dot(kernel, kernel.T)\n",
        "    kernel *= 100\n",
        "  \n",
        "    if bnddtls[2][1].item()+size > img_heatmap.shape[0]-1:\n",
        "                y_begin = img_heatmap.shape[0]-1-size\n",
        "    else:\n",
        "                y_begin = int(bnddtls[2][1].item())\n",
        "\n",
        "    if bnddtls[2][0].item()+size > img_heatmap.shape[1]-1:\n",
        "                x_begin = img_heatmap.shape[1]-1-size\n",
        "    else:\n",
        "                x_begin = int(bnddtls[2][0].item())\n",
        "\n",
        "    y_end = y_begin + (size)\n",
        "    x_end = x_begin + (size)\n",
        "    img_heatmap[y_begin : y_end, x_begin : x_end] = torch.from_numpy(kernel)\n",
        "    return img_heatmap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQsTrqbmXAhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays or PIL image in sample to Tensors.\"\"\"\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C X H X W\n",
        "\n",
        "    def __call__(self, sample):\n",
        "      items = dict()\n",
        "      for key in sample.keys():\n",
        "          if key == 'image':\n",
        "            image = sample[key]\n",
        "            image = F.to_tensor(image)\n",
        "            items[key] = image\n",
        "          else:\n",
        "            dtls = torch.FloatTensor(sample[key])\n",
        "            items[key] = dtls\n",
        "      return items"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-oa7fSrXHlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Rescale(object):\n",
        "    \"\"\"\n",
        "    Rescale the object to the size of given in output_size\n",
        "    Args:\n",
        "    output_size (tensor): required size of the output image\n",
        "    \"\"\"\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        items = dict()\n",
        "        image = sample['image']\n",
        "        w, h = image.size\n",
        "        if isinstance(self.output_size, int):\n",
        "           if h > w:\n",
        "              new_h, new_w = self.output_size * h / w, self.output_size\n",
        "           else:\n",
        "              new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "           new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        for key in sample.keys():\n",
        "          if key == 'image':\n",
        "              img = F.resize(image, (new_h, new_w))\n",
        "              items[key] = img\n",
        "          else:\n",
        "              all_dtls = sample[key]\n",
        "              \n",
        "              for i, dtls in enumerate(all_dtls):\n",
        "                  all_dtls[i][0] = np.round(dtls[0] * np.array([new_w / w, new_h / h]), 0)\n",
        "                  all_dtls[i][1] = np.round(dtls[1] * np.array([new_w / w, new_h / h]), 0)\n",
        "                  all_dtls[i][3] = np.abs([dtls[0, 0]-dtls[1, 0], dtls[0, 1]-dtls[1, 1]])\n",
        "                  all_dtls[i][2] = np.array([dtls[0, 0]+dtls[3, 0]/2, dtls[0, 1]+dtls[3, 1]/2])\n",
        "\n",
        "              items[key] = all_dtls\n",
        "              \n",
        "        return items"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6QQ01GrXIc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomVerticalFlip(object):\n",
        "    \"\"\"\n",
        "    Vertical flip the given PIL Image randomly with a given probability.\n",
        "    Args:\n",
        "    p (float): probability of the image being flipped. Default value is 0.5\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p=0.5):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, sample):\n",
        "      items = dict()\n",
        "      image = sample['image']\n",
        "      w, h = image.size\n",
        "      if random.random() < self.p:\n",
        "        for key in sample.keys():\n",
        "            if key == 'image':\n",
        "               image = F.vflip(image)\n",
        "               items[key] = image\n",
        "            else:\n",
        "              all_dtls = sample[key]\n",
        "              \n",
        "              for i, dtls in enumerate(all_dtls):\n",
        "                 if dtls[2][0] > 0 and dtls[2][1] > 0:\n",
        "                    dtls[0][1] = h-1-dtls[0][1]-dtls[3][1]\n",
        "                    dtls[1][1] = h-1-dtls[1][1]+dtls[3][1]\n",
        "                    dtls[2][1] = h-1-dtls[2][1]\n",
        "\n",
        "              items[key] = all_dtls\n",
        "      else:\n",
        "         return sample\n",
        "      return items"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWKqJDY90_-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomHorizontalFlip(object):\n",
        "    \"\"\"\n",
        "    Horizontally flip the given PIL Image randomly with a given probability.\n",
        "\n",
        "    Args:\n",
        "    p (float): probability of the image being flipped. Default value is 0.5\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p=0.5):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, sample):\n",
        "      items = dict()\n",
        "      image = sample['image']\n",
        "      w, h = image.size\n",
        "      \n",
        "      if random.random() < self.p:\n",
        "          for key in sample.keys():\n",
        "             if(key == 'image'):  \n",
        "                image = F.hflip(image)\n",
        "                items[key] = image\n",
        "             else:\n",
        "                all_dtls = sample[key]\n",
        "              \n",
        "                for i, dtls in enumerate(all_dtls):\n",
        "                   if dtls[2][0] > 0 and dtls[2][1] > 0:\n",
        "                      dtls[0][0] = w-1-dtls[0][0]-dtls[3][0]\n",
        "                      dtls[1][0] = w-1-dtls[1][0]+dtls[3][0]\n",
        "                      dtls[2][0] = w-1-dtls[2][0]\n",
        "\n",
        "                items[key] = all_dtls\n",
        "      else:\n",
        "         return sample\n",
        "      return items"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQg-uYD3XQ4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalizing the dataset\n",
        "class Normalize(object):\n",
        "    \"\"\"Normalize the image using mean and standard deviation provided.\n",
        "\n",
        "    Args:\n",
        "    mean(tensor): Mean of the guassian distribution to be used for normalization in \n",
        "    each dimension of the image.\n",
        "    std: Standard deviation of the guassian distribution to be used for normalization in \n",
        "    each dimension of the image.\n",
        "    \"\"\"\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        \"\"\" \n",
        "        Normalizes the image in each dimension as per the mean and std values.      \n",
        "        \"\"\"\n",
        "        items = dict()\n",
        "        for key in sample.keys():\n",
        "          if key == 'image':\n",
        "            image = sample[key]\n",
        "            items[key] = F.normalize(image, self.mean, self.std)\n",
        "          else:\n",
        "            items[key] = sample[key]\n",
        "        return items"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGXy8UnlXp4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lambda(object):\n",
        "    \"\"\"Apply a user-defined lambda as a transform.\n",
        "\n",
        "    Args:\n",
        "    lambd (function): Lambda/function to be used for transform.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lambd):\n",
        "        assert callable(lambd), repr(type(lambd).__name__) + \\\n",
        "            \" object is not callable\"\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.lambd(img)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '()'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqLkpd38XuCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ColorJitter(object):\n",
        "    \"\"\"Randomly change the brightness, contrast and saturation of an image.\n",
        "\n",
        "    Args:\n",
        "        brightness (float or tuple of float (min, max)): How much to jitter brightness.\n",
        "            brightness_factor is chosen uniformly from [max(0, 1 - brightness), 1 + brightness]\n",
        "            or the given [min, max]. Should be non negative numbers.\n",
        "        contrast (float or tuple of float (min, max)): How much to jitter contrast.\n",
        "            contrast_factor is chosen uniformly from [max(0, 1 - contrast), 1 + contrast]\n",
        "            or the given [min, max]. Should be non negative numbers.\n",
        "        saturation (float or tuple of float (min, max)): How much to jitter saturation.\n",
        "            saturation_factor is chosen uniformly from [max(0, 1 - saturation), 1 + saturation]\n",
        "            or the given [min, max]. Should be non negative numbers.\n",
        "        hue (float or tuple of float (min, max)): How much to jitter hue.\n",
        "            hue_factor is chosen uniformly from [-hue, hue] or the given [min, max].\n",
        "            Should have 0<= hue <= 0.5 or -0.5 <= min <= max <= 0.5.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0):\n",
        "        self.brightness = self._check_input(brightness, 'brightness')\n",
        "        self.contrast = self._check_input(contrast, 'contrast')\n",
        "        self.saturation = self._check_input(saturation, 'saturation')\n",
        "        self.hue = self._check_input(hue, 'hue', center=0, bound=(-0.5, 0.5),\n",
        "                                     clip_first_on_zero=False)\n",
        "\n",
        "    def _check_input(self, value, name, center=1, bound=(0, float('inf')), clip_first_on_zero=True):\n",
        "        if isinstance(value, numbers.Number):\n",
        "            if value < 0:\n",
        "                raise ValueError(\n",
        "                    \"If {} is a single number, it must be non negative.\".format(name))\n",
        "            value = [center - value, center + value]\n",
        "            if clip_first_on_zero:\n",
        "                value[0] = max(value[0], 0)\n",
        "        elif isinstance(value, (tuple, list)) and len(value) == 2:\n",
        "            if not bound[0] <= value[0] <= value[1] <= bound[1]:\n",
        "                raise ValueError(\n",
        "                    \"{} values should be between {}\".format(name, bound))\n",
        "        else:\n",
        "            raise TypeError(\n",
        "                \"{} should be a single number or a list/tuple with lenght 2.\".format(name))\n",
        "\n",
        "        # if value is 0 or (1., 1.) for brightness/contrast/saturation\n",
        "        # or (0., 0.) for hue, do nothing\n",
        "        if value[0] == value[1] == center:\n",
        "            value = None\n",
        "        return value\n",
        "\n",
        "    @staticmethod\n",
        "    def get_params(brightness, contrast, saturation, hue):\n",
        "        \"\"\"Get a randomized transform to be applied on image.\n",
        "\n",
        "        Arguments are same as that of __init__.\n",
        "\n",
        "        Returns:\n",
        "            Transform which randomly adjusts brightness, contrast and\n",
        "            saturation in a random order.\n",
        "        \"\"\"\n",
        "        tforms = []\n",
        "\n",
        "        if brightness is not None:\n",
        "            brightness_factor = random.uniform(brightness[0], brightness[1])\n",
        "            tforms.append(\n",
        "                Lambda(lambda img: F.adjust_brightness(img, brightness_factor)))\n",
        "\n",
        "        if contrast is not None:\n",
        "            contrast_factor = random.uniform(contrast[0], contrast[1])\n",
        "            tforms.append(\n",
        "                Lambda(lambda img: F.adjust_contrast(img, contrast_factor)))\n",
        "\n",
        "        if saturation is not None:\n",
        "            saturation_factor = random.uniform(saturation[0], saturation[1])\n",
        "            tforms.append(\n",
        "                Lambda(lambda img: F.adjust_saturation(img, saturation_factor)))\n",
        "\n",
        "        if hue is not None:\n",
        "            hue_factor = random.uniform(hue[0], hue[1])\n",
        "            tforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))\n",
        "\n",
        "        random.shuffle(tforms)\n",
        "        transform = transforms.Compose(tforms)\n",
        "\n",
        "        return transform\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sample (List): List of Input image and bounding box\n",
        "\n",
        "        Returns:\n",
        "            List: Color jittered image and original bounding box.\n",
        "        \"\"\"\n",
        "        items = dict()\n",
        "        for key in sample.keys():\n",
        "          if key == 'image':\n",
        "            image = sample[key]\n",
        "            transform = self.get_params(self.brightness, self.contrast,\n",
        "                                    self.saturation, self.hue)\n",
        "            items[key] =  transform(image)\n",
        "          else:\n",
        "            items[key] = sample[key]\n",
        "        return items\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RECjTBJMYLNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RobotDataset(Dataset):\n",
        "    \"\"\"Cutomized Dataset used to train the model.\n",
        "    Args:\n",
        "      root_dir: path where all the training files are saved.\n",
        "      transform: transformations to be applied to the dataset.\n",
        "      filenames: names of all the files in training dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "            \n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.filenames = []\n",
        "        for file in os.listdir(root_dir):\n",
        "            if file.endswith(\".jpg\") or file.endswith('.jpeg'):\n",
        "               self.filenames.append(file)\n",
        "    def __len__(self):\n",
        "        \"\"\"Length of the dataset\"\"\"\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        filepath =os.path.join(self.root_dir,self.filenames[ind])\n",
        "        image = Image.open(filepath)\n",
        "        if(filepath.endswith('.jpg')):\n",
        "          xml_data = ET.parse(filepath.replace('.jpg','.xml')).getroot()\n",
        "        elif(filepath.endswith('.jpeg')):\n",
        "          xml_data = ET.parse(filepath.replace('.jpeg','.xml')).getroot()        \n",
        "        all_dtls= []\n",
        "        \n",
        "        for group in xml_data.findall('object'):\n",
        "            bndvalues = group.find('bndbox')\n",
        "            all_dtls.append(find_bnddetails(bndvalues))       \n",
        "        sample = {'image': image, 'dtls': all_dtls}\n",
        "        if self.transform:\n",
        "            if type(self.transform) is not list:\n",
        "              self.transform = [self.transform]\n",
        "            for idx in range(len(self.transform)):\n",
        "                  sample = self.transform[idx](sample)\n",
        "        size = sample['image'].shape\n",
        "        heatmap_list = torch.zeros([4,int(size[1]/4),int(size[2]/4)])\n",
        "        i=0\n",
        "        for group in xml_data.findall('object'):\n",
        "            label = group.find('name').text\n",
        "            img_heatmap = HeatMap(sample['dtls'][i],(size[1],size[2]))\n",
        "            if(label == 'Head'):\n",
        "               heatmap_list[0] += img_heatmap\n",
        "            elif (label == 'Foot'):\n",
        "               heatmap_list[1] += img_heatmap \n",
        "            elif (label == 'Trunk'):\n",
        "               heatmap_list[2] += img_heatmap \n",
        "            elif (label == 'Hand'):\n",
        "               heatmap_list[3] += img_heatmap \n",
        "            i+=1  \n",
        "        dataset = {'image': sample['image'], 'heatmap': heatmap_list}\n",
        "        return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj3Q5nsOYMUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(Dataset):\n",
        "\n",
        "    \"\"\"Customized dataset used for testing the model.\n",
        "\n",
        "    Args:\n",
        "        root_dir: path where all the training files are saved.\n",
        "        transform: transformations to be applied to the dataset.\n",
        "        filenames: names of all the files in training dataset.\n",
        "        \n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "            \n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.filenames = []\n",
        "        for file in os.listdir(root_dir):\n",
        "            if file.endswith(\".jpg\"):\n",
        "               self.filenames.append(file)\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        filepath =os.path.join(self.root_dir,self.filenames[ind])\n",
        "        image = Image.open(filepath)\n",
        "        xml_data = ET.parse(filepath.replace('jpg','xml')).getroot()\n",
        "        head_dtls = np.zeros((3,4,2))\n",
        "        trunk_dtls = np.zeros((3,4,2))\n",
        "        hands_dtls = np.zeros((6,4,2))\n",
        "        foot_dtls = np.zeros((6,4,2))\n",
        "        head_idx = 0\n",
        "        trunk_idx = 0\n",
        "        hands_idx = 0\n",
        "        foot_idx = 0\n",
        "        for group in xml_data.findall('object'):\n",
        "            bndvalues = group.find('bndbox')\n",
        "            label = group.find('name').text\n",
        "            if(label == 'Head' and head_idx < 3):\n",
        "              head_dtls[head_idx] = find_bnddetails(bndvalues)\n",
        "              head_idx += 1\n",
        "            elif(label == 'Trunk' and trunk_idx < 3):\n",
        "              trunk_dtls[trunk_idx] = find_bnddetails(bndvalues)\n",
        "              trunk_idx += 1\n",
        "            elif(label == 'Foot' and foot_idx < 6):\n",
        "              foot_dtls[foot_idx] = find_bnddetails(bndvalues)\n",
        "              foot_idx += 1\n",
        "            elif(label == 'Hand' and hands_idx < 6):\n",
        "              hands_dtls[hands_idx] = find_bnddetails(bndvalues)\n",
        "              hands_idx += 1\n",
        "        sample = {'image': image, \n",
        "                  'head_dtls': head_dtls,\n",
        "                  'trunk_dtls':trunk_dtls,\n",
        "                  'hands_dtls':hands_dtls,\n",
        "                  'foot_dtls' : foot_dtls}\n",
        "        if self.transform:\n",
        "          if type(self.transform) is not list:\n",
        "              self.transform = [self.transform]\n",
        "          for idx in range(len(self.transform)):\n",
        "              sample = self.transform[idx](sample)\n",
        "        \n",
        "        return sample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8Pdo1yaYaVG",
        "colab_type": "code",
        "outputId": "ef6a78f7-6a80-4880-b7c6-18c32b326f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;34m': timeout during initial read of root folder; for more info: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             'https://research.google.com/colaboratory/faq.html#drive-timeout')\n\u001b[0;32m--> 233\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;31m# Not already authorized, so do the authorization dance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npa1VwmbYgDc",
        "colab_type": "code",
        "outputId": "cc01f16d-48e6-4664-e43a-2536a02955f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "transforms1 = [Rescale((480,640)),RandomHorizontalFlip(), RandomVerticalFlip(),\n",
        "                ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "                ToTensor(), Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
        "transforms2 = [Rescale((480,640)),ToTensor(), Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
        "train_dataset = RobotDataset(root_dir = '/content/drive/My Drive/dataset/blob/forceTrain',transform=transforms1)\n",
        "test_dataset = TestDataset(root_dir = '/content/drive/My Drive/dataset/blob/forceTest',transform=transforms2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cd968b3feb2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m transforms1 = [Rescale((480,640)),RandomHorizontalFlip(), RandomVerticalFlip(),\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mColorJitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrightness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 ToTensor(), Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n\u001b[1;32m      4\u001b[0m \u001b[0mtransforms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mRescale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.485\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.406\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobotDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/dataset/blob/forceTrain'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RandomHorizontalFlip' is not defined"
          ]
        }
      ]
    }
  ]
}